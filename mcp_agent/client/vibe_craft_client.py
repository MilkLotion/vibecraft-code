__author__ = "Se Hoon Kim(sehoon787@korea.ac.kr)"

# Standard imports
import os
from typing import Dict, Any

# Third-party imports
from langchain_mcp_adapters.client import MultiServerMCPClient

# Custom imports
from mcp_agent.client import VibeCraftAgentRunner
from mcp_agent.engine import (
    ClaudeEngine,
    OpenAIEngine,
    GeminiEngine
)
from mcp_agent.schemas.prompt_parser_schemas import VisualizationType
from mcp_agent.schemas import (
    MCPServerConfig,
    VisualizationRecommendationResponse
)
from utils import FileUtils, PathUtils
from utils.prompts import *


class VibeCraftClient:
    def __init__(self, engine: str):
        if engine == "claude":
            self.engine = ClaudeEngine()
        elif engine == "gemini":
            self.engine = GeminiEngine()
        elif engine == "gpt":
            self.engine = OpenAIEngine()
        else:
            raise ValueError("Not Supported Engine")
        self.client: Optional[MultiServerMCPClient] = None

        self.mcp_tools: Optional[List[MCPServerConfig]] = None  # common MCP tools
        self.topic_mcp_server: Optional[List[MCPServerConfig]] = None
        self.set_data_mcp_server: Optional[List[MCPServerConfig]] = None  # TODO: WIP

        self.tools: Optional[List] = None

        self.data: Optional[pd.DataFrame] = None

    """Engine Methods"""
    def get_thread_id(self) -> str:
        return str(self.engine.thread_id)

    def merge_chat_history(self, thread_id: str):
        self.engine.merge_chat_history(thread_id=thread_id)

    def load_chat_history(self, thread_id: str):
        self.engine.load_chat_history(thread_id=thread_id)

    async def load_tools(self, mcp_servers: Optional[List[MCPServerConfig]] = None):
        """
        Connect Multiple MCP servers with ClientSessionGroup, and integrate tools, prompts, resources.
        Save self.session
        """

        mcp_servers = mcp_servers or self.mcp_tools
        if mcp_servers:
            try:
                self.client = MultiServerMCPClient(
                    {
                        tool.name: {
                            "command": tool.command,
                            "args": tool.args,
                            "transport": tool.transport
                        }
                        for tool in mcp_servers
                    }
                )
                self.tools = await self.client.get_tools()
                self.engine.update_tools(self.tools)
                print(f"\nğŸ”Œ Connected to {', '.join([t.name for t in mcp_servers])}")
                print("Connected to server with tools:", [tool.name for tool in self.tools])
            except Exception as e:
                print(f"âš ï¸ ì„œë²„ ì—°ê²° ì‹¤íŒ¨: {', '.join([t.name for t in mcp_servers])} - {e}")

    async def execute_step(
        self, prompt: str, system: Optional[str] = None,
        use_langchain: Optional[bool] = True,
    ) -> str:
        if use_langchain:
            return await self.engine.generate_langchain(prompt=prompt, system=system)
        return await self.engine.generate(prompt=prompt)

    def get_summary(self) -> str:
        stats = self.engine.get_conversation_stats()
        if stats['has_summary']:
            return stats["summary"]
        else:
            self.engine.trigger_summarize()
            stats = self.engine.get_conversation_stats()
            return stats["summary"]

    """Topic Selection Methods"""
    async def topic_selection(self, topic_prompt: str) -> str:
        """Step 1: ì£¼ì œ ì„¤ì •"""
        await self.load_tools(self.topic_mcp_server)

        print("\nğŸš¦ Step 1: ì£¼ì œ ì„¤ì •")
        system, human = set_topic_prompt(topic_prompt)
        result = await self.execute_step(human, system)
        print(result)
        return result

    """Data loading and generation Methods"""
    async def set_data(self, file_path: Optional[str] = None) -> pd.DataFrame:
        """Step 2: ë°ì´í„° ì—…ë¡œë“œ ë˜ëŠ” ìƒì„±"""
        print("\nğŸš¦ Step 2: ë°ì´í„° ì—…ë¡œë“œ")
        await self.load_tools(self.set_data_mcp_server)

        if file_path:
            self.data = FileUtils.load_local_files([file_path])
        else:
            self.data = FileUtils.load_files()

        # ë°ì´í„° ìë™ ì „ì²˜ë¦¬ ë° ì €ì¥
        await self.auto_process_and_save_data()

        return self.data

    """Data processing Methods"""
    async def auto_process_and_save_data(self, df: Optional[pd.DataFrame] = None) -> pd.DataFrame:
        """Step 3: ë°ì´í„° ìë™ ì „ì²˜ë¦¬ ë° ì €ì¥ (ë‹¨ì¼ í”„ë¡¬í”„íŠ¸)"""
        if df is None:
            df = self.data

        print("\nğŸš¦ Step 3: ë°ì´í„° ìë™ ì „ì²˜ë¦¬ ë° ì €ì¥")

        # 1. ë°ì´í„° ì „ì²˜ë¦¬
        df = df.loc[:, ~df.columns.str.contains('^Unnamed')]
        df.columns = [FileUtils.normalize_column_name(col) for col in df.columns]
        print(f"\nğŸ“Š ë°ì´í„°í”„ë ˆì„ ì •ì œ ì™„ë£Œ:\n{df.head(3).to_string(index=False)}")

        # 2. ë‹¨ì¼ í”„ë¡¬í”„íŠ¸ë¡œ ì»¬ëŸ¼ ì‚­ì œ + ì˜ë¬¸ ë³€í™˜ í•œë²ˆì— ì²˜ë¦¬
        print("\nğŸ§¹ ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° ë° ì˜ë¬¸ ë³€í™˜ ì¤‘...")
        system, human = auto_process_data_prompt(df)
        result = await self.execute_step(human, system)
        print(f"\nğŸ¤– Agent ì²˜ë¦¬ ê²°ê³¼:\n{result}")

        # 3. ê²°ê³¼ íŒŒì‹± ë° ì ìš©
        new_col = FileUtils.parse_dict_flexible(result)
        filtered_new_col = {k: v for k, v in new_col.items() if v is not None}

        # ì»¬ëŸ¼ ë§¤í•‘ ì ìš© (dictionaryì— ì—†ëŠ” ì»¬ëŸ¼ì€ ìë™ ì œê±°ë¨)
        mapped_df = df.rename(columns=new_col)[list(filtered_new_col.values())]
        print(f"\nğŸ§± ìµœì¢… ë°ì´í„°:\n{mapped_df.head(3).to_string(index=False)}")

        # 4. íŒŒì¼ ì €ì¥
        path = PathUtils.generate_path(self.get_thread_id())
        mapped_df.to_csv(os.path.join(path, f"{self.get_thread_id()}.csv"), encoding="cp949", index=False)
        file_path = FileUtils.save_sqlite(mapped_df, path, self.get_thread_id())
        FileUtils.save_metadata(filtered_new_col, path, file_path)
        self.data = mapped_df

        return mapped_df

    """Code Generator Methods"""
    async def auto_recommend_visualization_type(self) -> VisualizationType:
        """Step 4: ì‹œê°í™” íƒ€ì… ìë™ ê²°ì •"""
        print("\nğŸš¦ Step 4: ì‹œê°í™” íƒ€ì… ìë™ ê²°ì •")

        stats = self.engine.get_conversation_stats()
        if stats['has_summary']:
            user_context = stats["summary"]
        else:
            self.engine.trigger_summarize()
            stats = self.engine.get_conversation_stats()
            user_context = stats["summary"]

        system, human = recommend_visualization_template_prompt(self.data, user_context)
        result = await self.execute_step(human, system)

        recommendations = FileUtils.parse_visualization_recommendation(result)
        response = VisualizationRecommendationResponse(
            user_context=user_context,
            recommendations=recommendations
        )

        # ê°€ì¥ ì‹ ë¢°ë„ ë†’ì€ ì‹œê°í™” íƒ€ì… ìë™ ì„ íƒ
        top_recommendation = response.get_top_recommendation()
        print(f"ğŸ’¡ ìë™ ì„ íƒëœ ì‹œê°í™” íƒ€ì…: {top_recommendation.visualization_type} (ì‹ ë¢°ë„: {top_recommendation.confidence}%)")

        return top_recommendation.visualization_type

    def run_code_generator(
            self, thread_id: str, visualization_type: VisualizationType,
            project_name: str = None, model: str = "pro"
    ) -> Dict[str, Any]:
        """ë™ê¸° ë°©ì‹ ì½”ë“œ ìƒì„±"""
        print("\nğŸš¦ Step 5: ì›¹ì•± ì½”ë“œ ìƒì„±")

        runner = VibeCraftAgentRunner()
        file_name = f"{thread_id}.sqlite"

        if not runner.is_available() or not PathUtils.is_exist(thread_id, file_name):
            return {"success": False, "message": "ì „ì œ ì¡°ê±´ í™•ì¸ ì‹¤íŒ¨"}

        file_path = PathUtils.get_path(thread_id, file_name)[0]
        output_dir = f"./output/{thread_id}"

        try:
            result = runner.run_agent(
                sqlite_path=file_path,
                visualization_type=visualization_type,
                user_prompt=self.get_summary(),
                output_dir=output_dir,
                project_name=project_name or f"vibecraft-{thread_id}",
                model=model
            )

            if result["success"]:
                print(f"âœ… ì½”ë“œ ìƒì„± ì™„ë£Œ: {result['output_dir']}")

            return result
        except Exception as e:
            return {"success": False, "message": str(e)}

    """Pipeline"""
    async def run_pipeline(self, topic_prompt: str, file_path: str):
        """
        ê°„ì†Œí™”ëœ ìë™ íŒŒì´í”„ë¼ì¸

        Args:
            topic_prompt: ë¶„ì„ ì£¼ì œ
            file_path: ë°ì´í„° íŒŒì¼ ê²½ë¡œ
        """
        # Step 1: ì£¼ì œ ì„¤ì •
        await self.topic_selection(topic_prompt)

        # Step 2: ë°ì´í„° ì—…ë¡œë“œ ë˜ëŠ” ìƒì„±
        await self.set_data(file_path)

        # ì´í›„ ìë™í™” í”„ë¡œì„¸ìŠ¤
        # Step 4: ì¸ê³¼ê´€ê³„ ë¶„ì„ (BaseEngineì—ì„œ ìë™ìœ¼ë¡œ RAG í™œìš©)
        print("\nğŸš¦ Step 4: ë°ì´í„° ì¸ê³¼ê´€ê³„ ë¶„ì„")
        analysis_query = f"ë‹¤ìŒ ë°ì´í„°ì˜ ì¸ê³¼ê´€ê³„ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”:\n{self.data.head(10).to_string()}"
        analysis_result = await self.execute_step(analysis_query)
        print(f"\nğŸ“Š ì¸ê³¼ê´€ê³„ ë¶„ì„ ê²°ê³¼:\n{analysis_result}")

        # Step 5: ì‹œê°í™” íƒ€ì… ìë™ ê²°ì •
        v_type = await self.auto_recommend_visualization_type()

        # Step 6: ì½”ë“œ ìë™ ìƒì„±
        print(f"\nğŸ’» ì‹œê°í™” íƒ€ì… '{v_type}'ìœ¼ë¡œ ì½”ë“œ ìƒì„±ì„ ì§„í–‰í•©ë‹ˆë‹¤...")
        result = self.run_code_generator(self.get_thread_id(), v_type)

        if result["success"]:
            print(f"\nâœ… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ! ìƒì„±ëœ ì½”ë“œ: {result['output_dir']}")
            return result
        else:
            print(f"\nâŒ ì½”ë“œ ìƒì„± ì‹¤íŒ¨: {result['message']}")
            return result

    async def chat_loop(self):
        """
        ëŒ€í™”í˜• ì±„íŒ… ë£¨í”„
        ì‚¬ìš©ìê°€ 'ì¢…ë£Œ', 'exit', 'quit' ë“±ì„ ì…ë ¥í•˜ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.
        """
        print("\nğŸ’¬ ì±„íŒ… ëª¨ë“œë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")
        print("ğŸ’¡ ì¢…ë£Œí•˜ë ¤ë©´ 'ì¢…ë£Œ', 'exit', 'quit' ì¤‘ í•˜ë‚˜ë¥¼ ì…ë ¥í•˜ì„¸ìš”.\n")

        # MCP ë„êµ¬ ë¡œë“œ (ì„ íƒì‚¬í•­ - í•„ìš”ì— ë”°ë¼ ì£¼ì„ í•´ì œ)
        # await self.load_tools(self.mcp_tools)

        exit_commands = ['ì¢…ë£Œ', 'exit', 'quit', 'ë‚˜ê°€ê¸°', 'q']

        while True:
            try:
                user_input = input("ğŸ¤ ì‚¬ìš©ì: ").strip()

                # ì¢…ë£Œ ëª…ë ¹ ì²´í¬
                if user_input.lower() in exit_commands:
                    print("\nğŸ‘‹ ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break

                # ë¹ˆ ì…ë ¥ ì²´í¬
                if not user_input:
                    print("âš ï¸ ë©”ì‹œì§€ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                    continue

                # AI ì‘ë‹µ ìƒì„±
                response = await self.execute_step(user_input)
                print(f"\nğŸ¤– AI: {response}\n")

                # ëŒ€í™” ê¸°ë¡ ì €ì¥
                self.engine.save_chat_history()

            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ Ctrl+Cë¥¼ ê°ì§€í–ˆìŠµë‹ˆë‹¤. ì±„íŒ…ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                break
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print("ê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
                continue_choice = input().strip().lower()
                if continue_choice != 'y':
                    break

        print("âœ… ì±„íŒ…ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

    async def test(self):
        print("ğŸ”¥ Run Test...")
        prompt = "ì£¼ì œë¥¼ ìë™ìœ¼ë¡œ ì„¤ì •í•´ì¤˜"

        # Run without Langchain
        result0 = await self.execute_step(prompt, use_langchain=False)
        print(f"\nğŸ¤– Run without tool and Langchain:\n{result0}\n")

        # Run Langchain
        result1 = await self.execute_step(prompt)
        print(f"\nğŸ¤– Langchain without tool:\n{result1}\n")

        while True:
            query = input("\nì‚¬ìš©ì: ").strip()
            result = await self.execute_step(query)
            print(result)

            self.engine.save_chat_history()
            self.merge_chat_history(thread_id="0d11b676-9cc5-4eb2-a90e-59277ca590fa")
            self.load_chat_history(thread_id="0d11b676-9cc5-4eb2-a90e-59277ca590fa")

    async def cleanup(self):
        self.client = None
